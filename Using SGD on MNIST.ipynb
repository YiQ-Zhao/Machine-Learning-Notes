{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "* What is pickle?\n",
    "https://docs.python.org/2/library/pickle.html\n",
    "* Random forest doesn't need to be normalized. \n",
    "* np.reshape(x_valid, (-1,28,28))\n",
    "* Einstein Summation http://mathworld.wolfram.com/EinsteinSummation.html\n",
    "* 3bluebrown linear algebra youtube\n",
    "* computational linear algebra fast.ai\n",
    "* kaiming he initialization tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarks:**\n",
    "* Random forests and decision trees are limited by the fact that they're basically doing nearest neighbors. They can't extrapolate out to, for example, what happens if I'll increase my prices by 20% and you've never priced at that level before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fastai.imports import *\n",
    "from fastai.torch_imports import *\n",
    "from fastai.io import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URL='http://deeplearning.net/data/mnist/'\n",
    "FILENAME='mnist.pkl.gz'\n",
    "\n",
    "def load_mnist(filename):\n",
    "    return pickle.load(gzip.open(filename, 'rb'), encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have any kind of Python object at all. you can use this build-in python library called pickle to dump it out onto your disk, share it around, load it up later, and you get back the same Python object you started with. Pickle is not just for pandas, it works for nearly every python object (but probably not likely optimal for nearly any Python object, so we use feather for df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mnist.pkl.gz: 16.2MB [00:01, 9.82MB/s]                            \n"
     ]
    }
   ],
   "source": [
    "get_data(URL+FILENAME, path+FILENAME)\n",
    "((x, y), (x_valid, y_valid), _) = load_mnist(path+FILENAME) # in this case we don't care about test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (50000, 784), numpy.ndarray, (50000,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x), x.shape, type(y), y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "784 = 28X28  \n",
    "The word flatten is very common with working with tensors. When you flatten a tensor, it means you're turning it into a lower rank tensor than your start up with.  \n",
    "* Vector, 1d array, rank 1 tensor  \n",
    "* Matrix, 2d array, rank 2 tensor\n",
    "* row = axis0, column = axis1\n",
    "* If you're an image person, then x is the first axis, y is the second axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many machine learning algorithms behave better when the data is *normalized*, that is when the mean is 0 and the standard deviation is 1. We will subtract off the mean and standard deviation from our training set in order to normalize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = x.mean()\n",
    "std = x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13044983, 0.30728981, -3.1638146e-07, 0.99999934)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=(x-mean)/std\n",
    "mean, std, x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question for students:\n",
    "Do you think it would be important to normalize the independent vairables for a random forest? NO. When we're deciding where to split, all that matters is the order. They totally ignore the outlier and only care about which one's higher than what other things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for consistency(with the parameters we learn when training), we subtract the mean and standard deviation of our training set from our validation set. The following example is from *Python Machine Learning*\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.0058509219, 0.99243325)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid = (x_valid-mean)/std\n",
    "x_valid.mean(), x_valid.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper methods  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show(img, title=None):\n",
    "    plt.imshow(img, interpolation='none', cmap=\"gray\")\n",
    "    if title is not None: plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plots(ims, figsize=(12,6), rows=2, titles=None):\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims)//rows\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None: sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation='none', cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* One shape dimension can be -1. In this case, the value is inferred from the length of the array and remaining dimensions. That being said, 10000*784/(28*28) = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_imgs = np.reshape(x_valid, (-1,28,28)); x_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/x2VQ9c6BSuMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f613c160cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(x_imgs[0], y_valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAAF0CAYAAADGqzQSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0kXt3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f613c184cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(x_imgs[:8], titles=y_valid[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "**What is a neural network?**  \n",
    "A *neural network* is an infinitely flexible function, consisting of *layers*. A *layer* is a linear function such as matrix multiplication followed by a non-linear function (the *activation*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With PyTorch, you can run it on the GPU rather than CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Launch a GPU computer on AWS:**  \n",
    "Launch Instances --> Community AMIs --> search fastai --> Select --> Select GPU compute --> p2.xlarge  \n",
    "(Check DL intro tutorial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net for Logistic Regression in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fastai.metrics import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.core import *\n",
    "\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin with the highest level abstraction: using a neural net defined by PyTorch's Sequential class.  \n",
    "Sequential means I'm going to give you a list of the layers that I want in my neural network. In this case, my list has two things in it. The first things says I want a linear layer, which is something that's going to do y = ax+b. So it is going to do a matrix product basically. So the input of the matrix product is going to be a vector of length 28 times 28 (pixels we have). The output needs to be of size 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(28*28, 10), #because we want 10 predictions [0,10]\n",
    "    nn.LogSoftmax()\n",
    ").cuda() \n",
    "# cuda tells pytorch to copy this neural network across to the GPU so from now on that network is going to \n",
    "# be actually running on the GPU. If we didn't say that it would run on the CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does ImageClassifierData.from_arrays do is it creates a PyTorch data loader for us. A PyTorch data loader is something that grabs a few images and sticks them to a mini batch that makes them available. In Python, we call these things generators. Generators are things where you can basically say I want another, I want another, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "md = ImageClassifierData.from_arrays(path, (x,y), (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss=nn.NLLLoss() #negative log likelihood loss\n",
    "metrics=[accuracy]\n",
    "opt=optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is creating a matrix multiplication followed by a non-linearity and that is trying to find the values of this matrix which fit the data as well as possible. Then we optimize the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_loss(y, p):\n",
    "    return np.mean(-(y * np.log(p) + (1-y) * np.log(1-p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.164252033486018"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acts = np.array([1, 0, 0, 1])\n",
    "preds = np.array([0.9, 0.1, 0.2, 0.8])\n",
    "binary_loss(acts, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the following code does is it goes through every images `epochs` (i.e. every image once in this case) and go into slightly update the values in that weight matrix based on those gradients. `crit` means the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e0c0d0161045fbb5a0aa4e78e68fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       0.31106  0.28607  0.91839]                        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(net, md, epochs=1, crit=loss, opt=opt, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = predcit(net, md.val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds.argmax(axis=1)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = preds.argmax(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [CHAPTER 4 A visual proof that neural nets can compute any function](neuralnetworksanddeeplearning.com/chap4.html)  \n",
    "* Kaiming He Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Defining Logistic Regression Ourselves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we used pytorch's `nn.Linear` to create a linear layer. This is defined by a matrix multiplication and then an addition (these are also called `affine transformations`). Let's try defining this ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as Numpy has `np.matmul` for matrix multiplication (in Python 3, this is equivalent to the @ operator), PyTorch has `torch.matmul`.\n",
    "\n",
    "Our PyTorch class needs two things: constructor (says what the parameters are) and a forward method (how to calculate a preduction using those parameters) The method `forward` describes how the neural net converts inputs to outputs.  \n",
    "\n",
    "In PyTorch, the optimizer knows to try to optmize any attribute of type **Parameter**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weights(*dims): return nn.Parameter(torch.randn(dims)/dims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogReg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # if you inherit from some other object, then you have to create the thing you inherit from first\n",
    "        self.l1_w = get_weights(28*28, 10) # Layer 1 weights\n",
    "        self.l1_b = get_weights(10)        # Layer 1 bias\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.matmul(x, self.l1_w) + self.l1_b # Linear Layer\n",
    "        x = torch.log(torch.exp(x)/(torch.exp(x).sum(dim=0))) # Non-linear (LogSoftmax) Layer\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Softmax:** (Activate function)\n",
    "* The softmax function takes our outputs and turns it into something which behaves like a probability. we don't strictly speaking need it we could still try train something which where the output directly is the probabilities, but by softmax it is less for the network to learn so it's going to learn better.  \n",
    "* Softmax will tend to make most of its activations pretty close to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we need define forward? This is a PyTorch specific thing. What's going to happen is when you create a module in PyTorch, the objects that you get back behaves as if it is a function. You can call it with parentheses. And so you need to somehow define when you call it as if it is a function. And the answer is PyTorch calls a method called forward. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our neural net and the optimizer. (We will use the ssame loss and metrics from above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net2 = LogReg().cuda()\n",
    "opt=optim.Adam(net2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "852449e103184207b64df145588a3941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       2.44033  2.39819  0.90914]                       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(net2, md, epochs=1, crit=loss, opt=opt, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to grab something that we can use to generate mini batches we have to take our data loader, and so you can ask for the training data loader from our model data object. You'll see there's a bunch of data loaders as you can ask for. \n",
    "```python\n",
    "md.sz\n",
    "md.test_aug_dl\n",
    "md.trn_y\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dl = iter(md.trn_dl) # turn something to a iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xmb, ymb = next(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same as \n",
    "```python\n",
    "for xmb, ymb in dl:\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does Variable() do?**\n",
    "This is how get free automatic differentiation.  \n",
    "```\n",
    "Docstring:     \n",
    "Wraps a tensor and records the operations applied to it.\n",
    "\n",
    "Variable is a thin wrapper around a Tensor object, that also holds\n",
    "the gradient w.r.t. to it, and a reference to a function that created it.\n",
    "This reference allows retracing the whole chain of operations that\n",
    "created the data. If the Variable has been created by the user, its grad_fn\n",
    "will be ``None`` and we call such objects *leaf* Variables.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.4245 -0.4245 -0.4245  ...  -0.4245 -0.4245 -0.4245\n",
       "-0.4245 -0.4245 -0.4245  ...  -0.4245 -0.4245 -0.4245\n",
       "-0.4245 -0.4245 -0.4245  ...  -0.4245 -0.4245 -0.4245\n",
       "          ...             â‹±             ...          \n",
       "-0.4245 -0.4245 -0.4245  ...  -0.4245 -0.4245 -0.4245\n",
       "-0.4245 -0.4245 -0.4245  ...  -0.4245 -0.4245 -0.4245\n",
       "-0.4245 -0.4245 -0.4245  ...  -0.4245 -0.4245 -0.4245\n",
       "[torch.cuda.FloatTensor of size 16x784 (GPU 0)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vxmb = Variable(xmb.cuda()) # Because our net2 object is in GPU, so our data should also be in GPU. xmb.cuda()\n",
    "vxmb # anything we do to Tensor we can do to a variable, but it's going to track of exactly what we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = net2(vxmb).exp() # this is what he mentioned above, a object behaves as a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 5 \n",
       " 7.6774e-03  2.7962e-02  1.2391e-01  2.3123e-02  2.8028e-04  6.3542e-03\n",
       " 1.0150e-03  7.6249e-02  2.7831e-01  8.4787e-03  1.0334e-02  5.7037e-02\n",
       " 3.1564e-04  5.1740e-01  1.3933e-02  6.0181e-03  3.9877e-02  1.1778e-02\n",
       "\n",
       "Columns 6 to 9 \n",
       " 1.9016e-02  2.1688e-07  1.0096e-02  5.3062e-07\n",
       " 1.8217e-02  9.9552e-02  6.2370e-02  3.1343e-02\n",
       " 1.0006e-02  7.2494e-02  1.8476e-01  1.7144e-01\n",
       "[torch.cuda.FloatTensor of size 3x10 (GPU 0)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So when we define our own architectures anywhere you would put in a function you could put in a layer, you can put it in a neural net. Because as PyTorch is concerned, they're all things that going to call just like as if they're functions. (?)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2\n",
       " 2\n",
       " 1\n",
       " 0\n",
       " 3\n",
       " 2\n",
       " 2\n",
       " 6\n",
       " 3\n",
       " 1\n",
       " 8\n",
       " 6\n",
       " 9\n",
       " 5\n",
       " 7\n",
       " 3\n",
       "[torch.cuda.LongTensor of size 16 (GPU 0)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.max(1)[1] # these are predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aisde about Broadcasting and Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's dig in to what we were doing with `torch.matmul:` matrix multiplication. First, let's start with a simpler building block: **broadcasting.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Element-wise operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting and element-wise operations are supported in the same way by both numpy and python.\n",
    "\n",
    "Operaters(+,-,\\*,/,>,<.==) are usually element-wise. \n",
    "\n",
    "Examples of element-wise operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10,  6, -4]), array([2, 8, 7]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([10, 6, -4])\n",
    "b = np.array([2, 8, 7])\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "  10\n",
       "   6\n",
       "  -4\n",
       " [torch.LongTensor of size 3], \n",
       "  2\n",
       "  8\n",
       "  7\n",
       " [torch.LongTensor of size 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = T([10, 6, -4])\n",
    "b = T([2, 8, 7])\n",
    "a,b "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  6, -4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False], dtype=bool)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a > 0 #rank one tensor vs. rank zero tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are we able to do a > 0? 0 is being broadcast to have the same dimensions as a.\n",
    "\n",
    "Remember above when we normalized our dataset by subtracting the mean(a scalar) from the entire data set (a matrix) and dividing by the standard deviation (anohter scalar)/ We wer using broadcasting!\n",
    "\n",
    "Other examples of broadcasting with a scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11,  7, -3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### broadcasting a vector to a matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also broadcast a vector to a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 20, 30])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.array([10, 20, 30]); c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11, 22, 33],\n",
       "       [14, 25, 36],\n",
       "       [17, 28, 39]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c + m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10],\n",
       "       [20],\n",
       "       [30]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(c, 1) # create a 3 x 1 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 20, 30]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None] # create a new axis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10],\n",
       "       [20],\n",
       "       [30]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:, None] # conver to 3 X 1, easier way to create a 3 X 1 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100, 200, 300],\n",
       "       [200, 400, 600],\n",
       "       [300, 600, 900]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None] * c[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 10, 10],\n",
       "       [20, 20, 20],\n",
       "       [30, 30, 30]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.broadcast_to(c[:, None], m.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When operating on two arrays, Numpy/PyTorch compares their shapes element-wise. It starts with the **trailing dimensions**, and works its way forward. Two dimensions are **compatible** when \n",
    "* they are equal, or\n",
    "* one of them is 1  \n",
    "\n",
    "Arrays do not need to have the same number of dimensions. For example, if you have a `256*256*3` array of RGB values, and you want to scale each color in the image by a different value, you can multiply the image by a one-dimensional array with 3 values. Lining up the sizes of the trailing axes of these arrays according to the broadcast rules, shows that they are compatible:  \n",
    "```\n",
    "Image (3d array): 256 x 256 x 3\n",
    "Scale (1d array):             3\n",
    "Result(3d array): 256 x 256 x 3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]]), array([[0, 1, 2, 3, 4]])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ogrid[0:5, 0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]]), array([[0, 1, 2, 3, 4]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg,yg = np.ogrid[0:5, 0:5]; xg, yg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]]), array([10, 20, 30]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([140, 320, 500])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m @ c # np.matmul(m, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10,  40,  90],\n",
       "       [ 40, 100, 180],\n",
       "       [ 70, 160, 270]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([140, 320, 500])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(m * c).sum(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Our Own Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, this is what we did above to write our own logistic regression class(as a pytorch neural net):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1_w = get_weights(28*28, 10) # Layer 1 weights\n",
    "        self.l1_b = get_weights(10)        # Layer 1 bias\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = x @ self.l1_w + self.l1_b\n",
    "        return torch.log(softmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = LogReg().cuda()\n",
    "opt=optim.Adam(net2.parameters())\n",
    "\n",
    "fit(net2, md, epochs=1, crit=loss, opt=opt, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we are using the fastai method fit to train our model. Now we will try writing the training loop oursellves.\n",
    "\n",
    "**Review question:** What does it mean to train a model?  \n",
    "\n",
    "We will use the LogReg class we created, as well as the same loss function, learning rate, and optimizer as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net2 = LogReg().cuda()\n",
    "loss=nn.NLLLoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer=optim.Adam(net2.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f2fcfa85888>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for t in range(100):\n",
    "    xt, yt = next(dl)\n",
    "    y_pred = net2(Variable(xt).cuda())\n",
    "    l = loss(y_pred, Variable(yt).cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put it all together in a training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(x, y):\n",
    "    y_pred = to_np(net2(V(x)))\n",
    "    return np.sum(y_pred.argmax(axis=1) == to_np(y))/len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Remark**: A variable keeps track of all of the steps to get computed.\n",
    "A very comprehensive introduction:\n",
    "[Variable](http://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net2 = LogReg().cuda()\n",
    "loss=nn.NLLLoss()\n",
    "learning_rate = 1e-2\n",
    "optimizer=optim.SGD(net2.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(1):\n",
    "    losses=[]\n",
    "    dl = iter(md.trn_dl)\n",
    "    for t in range(len(dl)):\n",
    "        # Forward pass: compute predicted y and loss by passing x to the model.\n",
    "        xt, yt = next(dl)\n",
    "        y_pred = net2(V(xt))\n",
    "        l = loss(y_pred, V(yt))\n",
    "        losses.append(l)\n",
    "\n",
    "        # Before the backward pass, use the optimizer object to zero all of the\n",
    "        # gradients for the variables it will update (which are the learnable weights of the model)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        l.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "    val_dl = iter(md.val_dl)\n",
    "    val_scores = [score(*next(val_dl)) for i in range(len(val_dl))]\n",
    "    print(np.mean(val_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
